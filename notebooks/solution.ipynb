{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e62bb9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Задание 1: Теоретическое описание задачи\n",
    "\n",
    "Задача извлечения именованных сущностей (Named Entity Recognition, NER) — это ключевая подзадача обработки естественного языка (NLP), направленная на автоматическое обнаружение и классификацию сущностей в неструктурированном тексте. К типичным категориям сущностей относятся:\n",
    "\n",
    "- `PER` — персоны (люди),\n",
    "- `ORG` — организации,\n",
    "- `LOC` — географические объекты,\n",
    "- `EVT` — события,\n",
    "- `PRO` — продукты или объекты.\n",
    "\n",
    "**Классические методы:**\n",
    "До распространения нейронных сетей основными подходами были:\n",
    "\n",
    "- Правила и шаблоны (rule-based systems),\n",
    "- Статистические модели: HMM (Hidden Markov Models), CRF (Conditional Random Fields),\n",
    "- Feature engineering — ручное составление признаков на основе лингвистических свойств.\n",
    "\n",
    "**Современные подходы (LLM):** \n",
    "\n",
    "С появлением больших языковых моделей (LLM) стало возможным извлечение сущностей в zero-shot или few-shot режимах, без дополнительного обучения. GigaChat, как представитель LLM, способен воспринимать структурированный prompt и возвращать списки сущностей, опираясь на контекст.\n",
    "\n",
    "**Метрики качества:**\n",
    "\n",
    "Для оценки качества предсказания применяются:\n",
    "\n",
    "Precision (точность),\n",
    "Recall (полнота),\n",
    "F1-score — гармоническое среднее между precision и recall.\n",
    "Оценка может проводиться:\n",
    "\n",
    "По каждой сущности (class-wise),\n",
    "В среднем (macro/micro-average)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d86cc5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 2: Загрузка и подготовка датасета\n",
    "\n",
    "**Формулировка:**  \n",
    "Реализуйте чтение датасета в pandas DataFrame с обязательными колонками:\n",
    "- `document_id`\n",
    "- `document_text`\n",
    "- `entity`\n",
    "- `gold_answer`\n",
    "\n",
    "Выведите шапку датафрейма.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c156fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>document_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brexit_ru.txt_file_10</td>\n",
       "      <td>EVT</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brexit_ru.txt_file_10</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Альбиона</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brexit_ru.txt_file_10</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Альбионе</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brexit_ru.txt_file_10</td>\n",
       "      <td>PER</td>\n",
       "      <td>Борис Джонсон Борис</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brexit_ru.txt_file_10</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Британии</td>\n",
       "      <td>Тереза Мэй рассчитывает усидеть в седле до зав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>brexit_ru.txt_file_1004</td>\n",
       "      <td>PER</td>\n",
       "      <td>Терезы</td>\n",
       "      <td>Борис Джонсон ушел в отставку с поста главы МИ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>brexit_ru.txt_file_1006</td>\n",
       "      <td>EVT</td>\n",
       "      <td>Brexit</td>\n",
       "      <td>Захарова лирически прокомментировала отставку ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>brexit_ru.txt_file_1006</td>\n",
       "      <td>PRO</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Захарова лирически прокомментировала отставку ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>brexit_ru.txt_file_1006</td>\n",
       "      <td>PER</td>\n",
       "      <td>Борис Джонсон Борис</td>\n",
       "      <td>Захарова лирически прокомментировала отставку ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>brexit_ru.txt_file_1006</td>\n",
       "      <td>PER</td>\n",
       "      <td>Бориса Джонсона Борис</td>\n",
       "      <td>Захарова лирически прокомментировала отставку ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                document_id entity            gold_answer  \\\n",
       "0     brexit_ru.txt_file_10    EVT                 Brexit   \n",
       "1     brexit_ru.txt_file_10    LOC               Альбиона   \n",
       "2     brexit_ru.txt_file_10    LOC               Альбионе   \n",
       "3     brexit_ru.txt_file_10    PER    Борис Джонсон Борис   \n",
       "4     brexit_ru.txt_file_10    LOC               Британии   \n",
       "..                      ...    ...                    ...   \n",
       "95  brexit_ru.txt_file_1004    PER                 Терезы   \n",
       "96  brexit_ru.txt_file_1006    EVT                 Brexit   \n",
       "97  brexit_ru.txt_file_1006    PRO               Facebook   \n",
       "98  brexit_ru.txt_file_1006    PER    Борис Джонсон Борис   \n",
       "99  brexit_ru.txt_file_1006    PER  Бориса Джонсона Борис   \n",
       "\n",
       "                                        document_text  \n",
       "0   Тереза Мэй рассчитывает усидеть в седле до зав...  \n",
       "1   Тереза Мэй рассчитывает усидеть в седле до зав...  \n",
       "2   Тереза Мэй рассчитывает усидеть в седле до зав...  \n",
       "3   Тереза Мэй рассчитывает усидеть в седле до зав...  \n",
       "4   Тереза Мэй рассчитывает усидеть в седле до зав...  \n",
       "..                                                ...  \n",
       "95  Борис Джонсон ушел в отставку с поста главы МИ...  \n",
       "96  Захарова лирически прокомментировала отставку ...  \n",
       "97  Захарова лирически прокомментировала отставку ...  \n",
       "98  Захарова лирически прокомментировала отставку ...  \n",
       "99  Захарова лирически прокомментировала отставку ...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "def load_annotations(annotation_dir: str) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for fname in os.listdir(annotation_dir):\n",
    "        if not fname.endswith('.out'):\n",
    "            continue\n",
    "        doc_id = os.path.splitext(fname)[0]\n",
    "        with open(os.path.join(annotation_dir, fname), encoding='utf-8') as f:\n",
    "            lines = [L.strip() for L in f if L.strip()]\n",
    "        if lines and lines[0] == doc_id.split('_')[-1]:\n",
    "            lines = lines[1:]\n",
    "        for line in lines:\n",
    "            parts = line.rsplit(None, 3)\n",
    "            if len(parts) >= 4:\n",
    "                surface, lemma, ent_type, canonical = parts\n",
    "                records.append({\n",
    "                    'document_id': doc_id,\n",
    "                    'entity': ent_type,\n",
    "                    'gold_answer': surface\n",
    "                })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def load_texts(text_dir: str, skip_lines: int = 4) -> pd.DataFrame:\n",
    "    records = []\n",
    "    for fname in os.listdir(text_dir):\n",
    "        if not fname.endswith('.txt'):\n",
    "            continue\n",
    "        doc_id = os.path.splitext(fname)[0]\n",
    "        with open(os.path.join(text_dir, fname), encoding='utf-8') as f:\n",
    "            lines = f.read().splitlines()\n",
    "        body = \"\\n\".join(lines[skip_lines:]).strip()\n",
    "        records.append({\n",
    "            'document_id': doc_id,\n",
    "            'document_text': body\n",
    "        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "from src.data_loader import load_annotations, load_texts\n",
    "\n",
    "\n",
    "\n",
    "ANN_DIR = '../data/annotations'\n",
    "TXT_DIR = '../data/raw'\n",
    "\n",
    "df_ann = load_annotations(ANN_DIR)\n",
    "df_txt = load_texts   (TXT_DIR)\n",
    "df     = df_ann.merge(df_txt, on='document_id', how='left')\n",
    "display(df.head(100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fbdd54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 3: Формирование prompt-функции для LLM\n",
    "\n",
    "**Формулировка:**  \n",
    "Напишите функцию, которая принимает на вход строку датафрейма и выдает текст входного сообщения для LLM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73438358",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 4: Ручное получение ответов от GigaChat и сохранение\n",
    "\n",
    "**Формулировка:**  \n",
    "Получите ответы GigaChat для всех документов. Документов всего 9, поэтому сделать это можно вручную, пользуясь веб-интерфейсом GigaChat или ботом в ВК или Телеграме. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7b3d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 5: Реализация метрики score_fn() и юнит-тесты\n",
    "\n",
    "**Формулировка:**  \n",
    "<сюда можно вставить формулировку из ТЗ>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acafbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 6: Расчёт метрик и визуализация по сущностям/документам\n",
    "\n",
    "**Формулировка:**  \n",
    "<сюда можно вставить формулировку из ТЗ>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5002f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 7: Анализ зависимости качества от длины документа\n",
    "\n",
    "**Формулировка:**  \n",
    "<сюда можно вставить формулировку из ТЗ>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5d37b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 8: Анализ ошибок, слабых и сильных сторон модели\n",
    "\n",
    "**Формулировка:**  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84574619",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Задание 9: Выводы по проекту и самооценка\n",
    "\n",
    "**Формулировка:**  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для задания 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
